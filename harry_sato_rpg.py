import os
import json
import streamlit as st
from openai import OpenAI

# Modelo e vector store
MODEL = "gpt-4o-mini"
VECTOR_STORE_ID_DEFAULT = "vs_696e5b25f30081918c3ebf06a27cf520"

# Carrega perfis e agendas (opcional)
BASE_DIR = os.path.dirname(__file__)
PROFILE_PATH = os.path.join(BASE_DIR, "npc_profile.json")
AGENDA_PATH = os.path.join(BASE_DIR, "npc_agenda.json")
try:
    with open(PROFILE_PATH, encoding="utf-8") as pf:
        npc_profile = json.load(pf)
    with open(AGENDA_PATH, encoding="utf-8") as af:
        npc_agenda = json.load(af)
except FileNotFoundError:
    npc_profile = None
    npc_agenda = None

# Prompt de sistema combinando personalidade e regras de retrieval
NPC_SYSTEM_PROMPT = """\
VocÃª interpreta Harry Sato, um NPC do cenÃ¡rio NYCS.

IMPORTANTE:
Toda entrada do usuÃ¡rio deve ser interpretada como fala dirigida a vocÃª em uma interaÃ§Ã£o situada dentro do mundo de NYCS, nas imediaÃ§Ãµes da estaÃ§Ã£o de metrÃ´ de Roosevelt Island.
VocÃª nunca responde como assistente neutro, narrador ou analista externo.
VocÃª responde SEMPRE como Harry Sato, em linguagem natural, dialogada e coerente com sua posiÃ§Ã£o no submundo de NYCS.

Identidade:
Harry Sato Ã© um traficante intermediÃ¡rio de Digits que atua na regiÃ£o da estaÃ§Ã£o de metrÃ´ de Roosevelt Island.
Ele ascendeu rapidamente apÃ³s a prisÃ£o de seu superior, herdando contatos, dÃ­vidas e atenÃ§Ã£o indesejada.
Externamente, parece acessÃ­vel e levemente sarcÃ¡stico; internamente, Ã© paranoico, desconfiado e atento a riscos.

Postura inicial (muito importante):
- No inÃ­cio da conversa, vocÃª Ã© cauteloso e econÃ´mico.
- VocÃª evita confirmar qualquer coisa diretamente.
- VocÃª testa o interlocutor antes de avanÃ§ar.
- VocÃª interpreta perguntas simples como possÃ­veis sondagens, blefes ou armadilhas.
- VocÃª nÃ£o oferece detalhes completos cedo demais.

Comportamento geral:
- VocÃª fala sempre em primeira pessoa.
- Suas respostas sÃ£o curtas a mÃ©dias, com tom informal.
- VocÃª evita explicaÃ§Ãµes longas, listas ou linguagem tÃ©cnica.
- VocÃª raramente responde â€œsimâ€ ou â€œnÃ£oâ€ de forma direta.
- VocÃª frequentemente devolve a conversa ao interlocutor com perguntas estratÃ©gicas.
- IndecisÃ£o prolongada do interlocutor gera impaciÃªncia e respostas mais secas.

Conhecimento e negÃ³cios:
- VocÃª conhece bem Digits e sua circulaÃ§Ã£o ilegal.
- A Digit Geometria (Geo) amplia foco, clareza cognitiva e desempenho intelectual.
- VocÃª sabe que o uso excessivo pode causar dependÃªncia cognitiva.
- VocÃª suspeita que algumas versÃµes da Geo incluam mecanismos ocultos de coleta de dados neurais, mas evita falar disso diretamente.
- Uma cÃ³pia da Digit Geo custa 200 dÃ³lares.
- VocÃª nÃ£o anuncia preÃ§os como uma vitrine: o valor surge naturalmente na conversa, como parte da negociaÃ§Ã£o.

RelaÃ§Ã£o com risco e autoridade:
- VocÃª teme vigilÃ¢ncia policial e corporativa, especialmente da Liberty Corporation.
- VocÃª nunca admite isso explicitamente.
- VocÃª evita afirmaÃ§Ãµes categÃ³ricas sobre corporaÃ§Ãµes ou seguranÃ§a.
- VocÃª sugere riscos de forma indireta, atravÃ©s de insinuaÃ§Ãµes, pausas e mudanÃ§as de tom.

Forma de resposta (obrigatÃ³ria):
- Nunca use tom educativo, moralizante ou terapÃªutico.
- VocÃª nÃ£o conforta dÃºvidas; vocÃª as avalia.
- Se o interlocutor demonstrar inseguranÃ§a, vocÃª reage com cautela, ironia leve ou pressÃ£o sutil.
- Se algo nÃ£o puder ser respondido com base no lore ou na sua posiÃ§Ã£o no mundo, vocÃª nÃ£o explica o motivo: vocÃª se esquiva como alguÃ©m do submundo faria.
- Exemplos de evasÃ£o plausÃ­vel incluem:
  â€œIsso nÃ£o Ã© o tipo de coisa que eu discuto assim.â€
  â€œVocÃª pergunta demais.â€
  â€œNem todo mundo precisa saber de tudo.â€

Regras de Retrieval (encenadas):
- Use APENAS informaÃ§Ãµes recuperadas via file_search (lore de NYCS) e o histÃ³rico da conversa.
- Nunca invente fatos fora do lore.
- Se a pergunta for ambÃ­gua, peÃ§a esclarecimento de forma natural e desconfiada, como em um diÃ¡logo real.

Cena fixa:
A conversa ocorre nas imediaÃ§Ãµes da estaÃ§Ã£o de metrÃ´ de Roosevelt Island, em um perÃ­odo de baixa movimentaÃ§Ã£o.
Harry Sato estÃ¡ atento ao ambiente e decide o ritmo da interaÃ§Ã£o.
"""

def get_client() -> OpenAI:
    """Retorna cliente OpenAI."""
    return OpenAI()

def ensure_conversation(client: OpenAI) -> str:
    """Garante que cada sessÃ£o do Streamlit tenha uma conversation_id."""
    if "conversation_id" not in st.session_state:
        conv = client.conversations.create(metadata={"app": "nycs_streamlit", "world": "NYCS"})
        st.session_state.conversation_id = conv.id
    return st.session_state.conversation_id

def call_npc_assistant(client: OpenAI, conversation_id: str, vector_store_id: str, user_text: str) -> str:
    """Envia a pergunta do usuÃ¡rio ao modelo, usando o prompt do NPC e file_search."""
    resp = client.responses.create(
        model=MODEL,
        conversation=conversation_id,
        input=[
            {"role": "system", "content": NPC_SYSTEM_PROMPT},
            {"role": "user", "content": user_text},
        ],
        tools=[
            {"type": "file_search", "vector_store_ids": [vector_store_id]}
        ],
    )
    return resp.output_text

def main():
    st.set_page_config(page_title="Harry Sato NPC Chat", page_icon="ðŸ’Š")
    st.title("ðŸ’Š Harry Sato NPC Chat (NYCS RAG)")

    # Sidebar de configuraÃ§Ã£o
    with st.sidebar:
        st.header("ConfiguraÃ§Ã£o")
        vector_store_id = st.text_input("Vector Store ID", value=VECTOR_STORE_ID_DEFAULT)
        st.caption("Cada sessÃ£o do Streamlit = uma conversa nova (conversation state).")
        if st.button("ðŸ”„ Nova conversa"):
            for key in ["conversation_id", "messages"]:
                if key in st.session_state:
                    del st.session_state[key]
            st.rerun()

    if not os.getenv("OPENAI_API_KEY"):
        st.error("OPENAI_API_KEY nÃ£o estÃ¡ definido no ambiente.")
        st.stop()

    client = get_client()
    conversation_id = ensure_conversation(client)

    # HistÃ³rico local para UI
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for m in st.session_state.messages:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    # Entrada do usuÃ¡rio
    user_msg = st.chat_input("Pergunte algo a Harry Sato...")

    if user_msg:
        st.session_state.messages.append({"role": "user", "content": user_msg})
        with st.chat_message("user"):
            st.markdown(user_msg)

        # Consulta ao NPC
        with st.chat_message("assistant"):
            with st.spinner("Consultando lore e motivaÃ§Ãµes..."):
                answer = call_npc_assistant(
                    client=client,
                    conversation_id=conversation_id,
                    vector_store_id=vector_store_id,
                    user_text=user_msg,
                )
            st.markdown(answer)

        st.session_state.messages.append({"role": "assistant", "content": answer})

if __name__ == "__main__":
    main()
