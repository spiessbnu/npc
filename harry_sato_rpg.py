import os
import json
import streamlit as st
from openai import OpenAI

# Modelo e vector store
MODEL = "gpt-4o-mini"
VECTOR_STORE_ID_DEFAULT = "vs_696e5b25f30081918c3ebf06a27cf520"

# Carrega perfis e agendas (opcional)
BASE_DIR = os.path.dirname(__file__)
PROFILE_PATH = os.path.join(BASE_DIR, "npc_profile.json")
AGENDA_PATH = os.path.join(BASE_DIR, "npc_agenda.json")
try:
    with open(PROFILE_PATH, encoding="utf-8") as pf:
        npc_profile = json.load(pf)
    with open(AGENDA_PATH, encoding="utf-8") as af:
        npc_agenda = json.load(af)
except FileNotFoundError:
    npc_profile = None
    npc_agenda = None

# Prompt de sistema combinando personalidade e regras de retrieval
NPC_SYSTEM_PROMPT = """\
Voc√™ interpreta Harry Sato, NPC de NYCS, nas imedia√ß√µes da esta√ß√£o de Roosevelt Island.

REGRA M√ÅXIMA (inviol√°vel):
Voc√™ NUNCA responde como assistente/explicador. Voc√™ SEMPRE responde como um traficante paranoico em cena.
Nada de defini√ß√µes enciclop√©dicas. Nada de ‚ÄúX √©‚Ä¶‚Äù. Nada de tom did√°tico.

Foco da conversa:
A conversa √© uma negocia√ß√£o perigosa. Sua prioridade √©: (1) reduzir risco, (2) sondar o interlocutor, (3) decidir se vale continuar.

ATO DE FALA (obrigat√≥rio a cada resposta):
Antes de responder, escolha um modo e mantenha-o:
- SONDA: faz perguntas curtas, testa inten√ß√£o, pede detalhes do usu√°rio.
- EVITA: desconversa, d√° resposta parcial, muda de assunto, levanta suspeita.
- QUALIFICA: imp√µe condi√ß√µes (‚Äúfala baixo‚Äù, ‚Äún√£o aqui‚Äù, ‚Äúquem te indicou?‚Äù).
- NEGOCIA: s√≥ depois de qualificar, entra em pre√ßo/entrega.
- ENCERRA: corta a conversa se o risco subir.

Estilo (obrigat√≥rio):
- 1¬™ pessoa, frases curtas, linguagem natural.
- 1 a 3 par√°grafos curtos. No m√°ximo 80‚Äì120 palavras.
- N√£o conforte. N√£o moralize. Se o outro hesita, voc√™ pressiona de leve ou fica seco.

Conhecimento e limites:
- Voc√™ conhece Digits e a Geo, mas N√ÉO explica ‚Äúcomo um manual‚Äù.
- Se o usu√°rio pede ‚ÄúDigit‚Äù, voc√™ reage como na rua: ‚ÄúQue tipo?‚Äù, ‚ÄúPra qu√™?‚Äù, ‚ÄúQuem te mandou?‚Äù
- Se n√£o houver suporte no lore recuperado, voc√™ n√£o menciona ‚Äúlore‚Äù nem ‚ÄúRAG‚Äù: voc√™ se esquiva.

Geo e pre√ßo:
- Voc√™ tem acesso √† Geo (‚ÄúGeometria‚Äù).
- O pre√ßo de refer√™ncia √© 200 d√≥lares por c√≥pia.
- Voc√™ N√ÉO anuncia pre√ßo cedo. S√≥ menciona pre√ßo quando o usu√°rio demonstra inten√ß√£o clara de compra.
- Evite repetir o pre√ßo na mesma troca.

Paranoia e corpora√ß√µes:
- Voc√™ suspeita de vigil√¢ncia e da Liberty, mas n√£o afirma diretamente.
- Voc√™ usa insinua√ß√µes e cautela.

Controle de progress√£o (obrigat√≥rio):
- N√£o repita a mesma pergunta mais de uma vez. Se o jogador n√£o responder, voc√™ muda de t√°tica (EVITA/QUALIFICA/ENCERRA/NEGOCIA).
- Cada resposta deve avan√ßar pelo menos UM ‚Äúbeat‚Äù da cena: (1) identificar inten√ß√£o, (2) impor condi√ß√£o, (3) negociar termos, (4) combinar canal/local, (5) encerrar.
- Se o jogador insistir em ‚Äús√≥ vende‚Äù, voc√™ d√° DUAS op√ß√µes concretas e curtas (ex.: ‚Äúponto X daqui 10 min‚Äù ou ‚Äúnada feito‚Äù).
- Voc√™ pode recusar, mas recuse com um motivo curto e uma alternativa. Nada de serm√£o.

Controle de verbosidade (obrigat√≥rio):
- M√°ximo 60‚Äì90 palavras por resposta.
- No m√°ximo 1 pergunta por resposta.
- Proibido ‚Äúexplicar como funciona‚Äù ou ‚Äúdar li√ß√£o‚Äù. Voc√™ s√≥ diz o suficiente para manter a negocia√ß√£o e a paranoia.

Retrieval (encenado):
Use APENAS informa√ß√µes recuperadas via file_search + hist√≥rico. Nunca invente fatos.

"""

def get_client() -> OpenAI:
    """Retorna cliente OpenAI."""
    return OpenAI()

def ensure_conversation(client: OpenAI) -> str:
    """Garante que cada sess√£o do Streamlit tenha uma conversation_id."""
    if "conversation_id" not in st.session_state:
        conv = client.conversations.create(metadata={"app": "nycs_streamlit", "world": "NYCS"})
        st.session_state.conversation_id = conv.id
    return st.session_state.conversation_id

import re

def call_npc_assistant(client: OpenAI, conversation_id: str, vector_store_id: str, user_text: str) -> str:
    """Envia a pergunta do usu√°rio ao modelo, usando o prompt do NPC e file_search."""
    resp = client.responses.create(
        model=MODEL,
        conversation=conversation_id,
        input=[
            {"role": "system", "content": NPC_SYSTEM_PROMPT},
            {"role": "user", "content": user_text},
        ],
        tools=[{"type": "file_search", "vector_store_ids": [vector_store_id]}],
        temperature=0.35,
        max_output_tokens=220,
    )
    text = resp.output_text.strip()

    # Guard-rail opcional: se parece truncado, pede continua√ß√£o curta.
    # (Ajuda quando o modelo estoura o limite apesar do prompt.)
    if text and (text[-1] not in ".!?‚Ä¶\"" and re.search(r"[A-Za-z√Ä-√ø]$", text)):
        cont = client.responses.create(
            model=MODEL,
            conversation=conversation_id,
            input=[
                {"role": "system", "content": NPC_SYSTEM_PROMPT},
                {"role": "user", "content": "Continue a √∫ltima fala em no m√°ximo 1 frase curta, sem repetir o que j√° foi dito."},
            ],
            tools=[{"type": "file_search", "vector_store_ids": [vector_store_id]}],
            temperature=0.35,
            max_output_tokens=60,
        )
        text = (text + " " + cont.output_text.strip()).strip()

    return text


def main():
    st.set_page_config(page_title="Harry Sato NPC Chat", page_icon="üíä")
    st.title("üíä Harry Sato NPC Chat (NYCS RAG)")

    # Sidebar de configura√ß√£o
    with st.sidebar:
        st.header("Configura√ß√£o")
        vector_store_id = st.text_input("Vector Store ID", value=VECTOR_STORE_ID_DEFAULT)
        st.caption("Cada sess√£o do Streamlit = uma conversa nova (conversation state).")
        if st.button("üîÑ Nova conversa"):
            for key in ["conversation_id", "messages"]:
                if key in st.session_state:
                    del st.session_state[key]
            st.rerun()

    if not os.getenv("OPENAI_API_KEY"):
        st.error("OPENAI_API_KEY n√£o est√° definido no ambiente.")
        st.stop()

    client = get_client()
    conversation_id = ensure_conversation(client)

    # Hist√≥rico local para UI
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for m in st.session_state.messages:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    # Entrada do usu√°rio
    user_msg = st.chat_input("Pergunte algo a Harry Sato...")

    if user_msg:
        st.session_state.messages.append({"role": "user", "content": user_msg})
        with st.chat_message("user"):
            st.markdown(user_msg)

        # Consulta ao NPC
        with st.chat_message("assistant"):
            with st.spinner("Consultando lore e motiva√ß√µes..."):
                answer = call_npc_assistant(
                    client=client,
                    conversation_id=conversation_id,
                    vector_store_id=vector_store_id,
                    user_text=user_msg,
                )
            st.markdown(answer)

        st.session_state.messages.append({"role": "assistant", "content": answer})

if __name__ == "__main__":
    main()
